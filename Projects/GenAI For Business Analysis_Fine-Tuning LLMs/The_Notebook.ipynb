{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1Rp80dTGpsDD",
        "0r2XnfwnqTCK",
        "Jo9HFdW0jput",
        "4XB-sFc3kO4A",
        "8lGyZnvk25q9"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome To The Notebook"
      ],
      "metadata": {
        "id": "2AqPte8bet51"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1 - Set up the project environment"
      ],
      "metadata": {
        "id": "1Rp80dTGpsDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==1.7.2 python-dotenv"
      ],
      "metadata": {
        "id": "lx4wV2MIUJ8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing modules"
      ],
      "metadata": {
        "id": "qypdUNULptjB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFmEp0r5T2eI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os, time\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Modules are imported.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up the OpenAI API:\n",
        "\n",
        "* Prepare a .env file to store the OpenAI API key.\n",
        "* Uploading the .env file to our colab environment\n",
        "* Load the API key and setup the API"
      ],
      "metadata": {
        "id": "XfVAcV_XqDja"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rbXC4QM4qCBe"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating OpenAI Client"
      ],
      "metadata": {
        "id": "rWxipGQIpxH8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nHj-RaA5p0WE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2 - Prepare the training data"
      ],
      "metadata": {
        "id": "0r2XnfwnqTCK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the provided `Customer Complaints.csv`\n",
        "\n"
      ],
      "metadata": {
        "id": "-_Alc-CyuHmE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jan2OKk5qW1J"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting the Complaints records to json**\n",
        "\n",
        "To be able to use the data for the fine-tuning purpose, we first need to convert each row of the dataframe into the following format:\n",
        "\n",
        "<pre>\n",
        "<code>\n",
        "{\n",
        "  <span style=\"color: blue;\">\"messages\"</span>: [\n",
        "    {\n",
        "      <span style=\"color: blue;\">\"role\"</span>: <span style=\"color: red;\">\"system\"</span>,\n",
        "      <span style=\"color: blue;\">\"content\"</span>: \"<span style=\"color: green;\">Providing context about the user's prompt.\n",
        "                  It may include information about the task,\n",
        "                  instructions, or background details relevant\n",
        "                  to the conversation.</span>\"\n",
        "    },\n",
        "    {\n",
        "      <span style=\"color: blue;\">\"role\"</span>: <span style=\"color: red;\">\"user\"</span>,\n",
        "      <span style=\"color: blue;\">\"content\"</span>: \"<span style=\"color: green;\">the prompt or input provided by the user,\n",
        "                  which typically initiates the conversation with the assistant.</span>\"\n",
        "    },\n",
        "    {\n",
        "      <span style=\"color: blue;\">\"role\"</span>: <span style=\"color: red;\">\"assistant\"</span>,\n",
        "      <span style=\"color: blue;\">\"content\"</span>: \"<span style=\"color: green;\">The desired response or output generated by\n",
        "                  the assistant in response to the user's prompt.</span>\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "</code>\n",
        "</pre>\n",
        "\n",
        "Let's get started!"
      ],
      "metadata": {
        "id": "uIK863G-qvMN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define a method that get's a row of the dataframe and convert it into the json format"
      ],
      "metadata": {
        "id": "fWVCfuvRjdXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_as_json(row):\n",
        "\n",
        "  system_content = \"\"\"\n",
        "      Given a customer complaint text, extract and return the following information in json (dict) format:\n",
        "      - Topic: The product/department that the customer has a complaint about.\n",
        "      - Problem: A two or three-word description of what exactly the problem is.\n",
        "      - Customer_Dissatisfaction_Index: is a number between 0 and 100 showing\n",
        "             how angry the customer is about the problem.\n",
        "  \"\"\"\n",
        "\n",
        "  formatted_data = {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": system_content},\n",
        "            {\"role\": \"user\", \"content\": row.Complaints},\n",
        "            {\"role\": \"assistant\", \"content\": row.Details}\n",
        "        ]\n",
        "      }\n",
        "\n",
        "  with open(\"training_data.json\", \"a\") as json_file:\n",
        "        json.dump(formatted_data, json_file)\n",
        "        json_file.write(\"\\n\")"
      ],
      "metadata": {
        "id": "-tHnvRamq5NK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's use of this method to generate the `training_data.json`"
      ],
      "metadata": {
        "id": "K3haPgzI-ClF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LNOMxwSX8dE4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3 - Fine-tune GPT 3.5 based on our training data"
      ],
      "metadata": {
        "id": "Jo9HFdW0jput"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's import the json file we prepared as our training data"
      ],
      "metadata": {
        "id": "h4TMhzSNj4hH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ExJ2cRU5-XtH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the Fine Tuning Job"
      ],
      "metadata": {
        "id": "TiBcO3I0kIU5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BXJB348zkMSx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's retrieve the state of the fine-tune"
      ],
      "metadata": {
        "id": "u7XWcO_7kzY6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hpbHjWu3AS4k"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 4 - Evaluate model"
      ],
      "metadata": {
        "id": "4XB-sFc3kO4A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's retrieve the event messages to check out the learning process of our fine-tuning job."
      ],
      "metadata": {
        "id": "p_3bNsW3k_eR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O2bif68aIEGJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's extract the training loss in each learning step"
      ],
      "metadata": {
        "id": "Pe3jUJJjyeO1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oqhDoVBNzW_w"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use a line chart to visualize the train_loss in each step"
      ],
      "metadata": {
        "id": "iiiJIUuq2W4D"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EMRvEd-F2bLO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 5 - Deploy our model"
      ],
      "metadata": {
        "id": "8lGyZnvk25q9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at `retrieved_job` again"
      ],
      "metadata": {
        "id": "EYljL-wH42ce"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q4ChDCWo3H85"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a method to extract information from a given user complaint using a specific LLM and return the results."
      ],
      "metadata": {
        "id": "nLLfuwC4-h9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_details(user_complaint, model_name):\n",
        "    \"\"\"\n",
        "    This function extracts information from a given user complaint using a specific LLM (Large Language Model).\n",
        "\n",
        "    Parameters:\n",
        "    user_complaint (str): The text of the user's complaint.\n",
        "    model_name (str): The name of the specific LLM model to use for extraction.\n",
        "    \"\"\"\n",
        "\n",
        "    system_content = \"\"\"\n",
        "        Given a customer complaint text, extract and return the following information in JSON (dict) format:\n",
        "        - Topic\n",
        "        - Problem\n",
        "        - Customer_Dissatisfaction_Index\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate a response using the specified model and the user's complaint\n",
        "    response = client.chat.completions.create(\n",
        "        model = model_name,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_content},  # System content explaining the expected output\n",
        "            {\"role\": \"user\", \"content\": user_complaint}  # User's complaint passed as content\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Return the content of the generated response\n",
        "    return response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "P3_99_Hf5CV1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use our fine-tuned model to extract the details for the following user complaint:\n",
        "\n",
        "*TV channels keep disappearing from my subscription! What's going on? Extremely annoyed with this service!*"
      ],
      "metadata": {
        "id": "zE_O2zAwplof"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vD1dEjnzWTuw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test our `GPT-4` model with the same user complaint"
      ],
      "metadata": {
        "id": "LJNgLZoS6-gw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G2XBuw0N47AC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try for the following complaint:\n",
        "\n",
        "*Line is down! It is really annoying!*"
      ],
      "metadata": {
        "id": "J3xZBAUitpVq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I3O6HzK_ttZ7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's compare the results from GPT-4"
      ],
      "metadata": {
        "id": "W4zeLRZfuNmS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6ubUkjXXuQ8X"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that our model, which is trained on our dataset, provides better answers compared to GPT-4. Our model is fine-tuned based on our data and is familiar with the different edge cases and the context of our dataset."
      ],
      "metadata": {
        "id": "YvqSymjWueXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customer_complaint = \"I am very Angry! I want my money back!\""
      ],
      "metadata": {
        "id": "wVQQfAAXy-v8"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}