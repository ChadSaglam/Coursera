{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q082WDnkLcGY"
      },
      "source": [
        "# Welcome to the Practice Task\n",
        "\n",
        "You've been hired by BookzOn, a growing e-book platform, which has provided a dataset containing the embedding vectors of 14 different e-books. They want to better understand their catalog by grouping these e-books into 3 distinct clusters based on their embedding vectors, which represent various features of the content.\n",
        "\n",
        "Your task is to use K-Means Clustering to categorize the e-books into 3 groups to help BookzOn optimize their recommendations.\n",
        "\n",
        "Good luck! 🍀\n",
        "\n",
        "— Ahmad\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following block to install `pyspark` module"
      ],
      "metadata": {
        "id": "b_0qPlclao37"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqgebMAwRfNo"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWZZxR7uVPw1"
      },
      "source": [
        "----\n",
        "Run the following block to import the necessary modules.\n",
        "\n",
        "**Do not forget to upload the `practice_task_data.csv` into the Google Colab environment.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scn7mBZ6J_xW"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import concat_ws\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import ArrayType, FloatType\n",
        "from pyspark.ml.feature import VectorAssembler, PCA\n",
        "from pyspark.ml.clustering import KMeans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJSqEXllRfNo"
      },
      "source": [
        "Create the spark session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73EXf737RfNo"
      },
      "outputs": [],
      "source": [
        "# write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkVUW9l-RPFY"
      },
      "source": [
        "Let's load the dataset `practice_task_data.csv` into a spark dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBs5gSZbS_GV"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"practice_task_data.csv\")\n",
        "# store the feature names\n",
        "features_column_names = [f\"feature_{i}\" for i in range(1, 513)]\n",
        "# update the column names\n",
        "df.columns = features_column_names\n",
        "# convert tha pandas dataframe to a spark dataframe\n",
        "data = spark.createDataFrame(df)\n",
        "\n",
        "data.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assemble the 512 Embedding Columns into a Single `features` Column using `VectorAssembler`."
      ],
      "metadata": {
        "id": "QVGiIJZC22Yo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uCBdSiRb23Wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select only the `features` column"
      ],
      "metadata": {
        "id": "BQcXhZVgX640"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c-adSOAmX_dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzWEWVmYW7Sv"
      },
      "source": [
        " > Use `K-means` clustering to group the articles into 3 groups."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09hycmOtW5qh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}