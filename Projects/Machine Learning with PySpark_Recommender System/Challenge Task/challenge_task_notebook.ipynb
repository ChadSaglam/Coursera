{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q082WDnkLcGY"
      },
      "source": [
        "# Welcome to the Challenge Task\n",
        "\n",
        "\n",
        "After successfully clustering the e-books, BookzOn is now asking for a more in-depth analysis of the results. They want to visualize the features and clusters for easier interpretation and insights. Your challenge is to apply PCA (Principal Component Analysis) to reduce the dimensionality of the embedding vectors and then visualize the clustered e-books in a 2D space.\n",
        "\n",
        "The task involves:\n",
        "\n",
        "1.   Apply PCA to reduce the embedding vectors to 2 principal components.\n",
        "2.   Visualize the 2D projection of the e-books and highlight the clusters.\n",
        "\n",
        "This will help BookzOn visually assess how distinct the clusters are and how the e-books relate to one another.\n",
        "\n",
        "Good luck! üçÄ\n",
        "\n",
        "‚Äî Ahmad\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following block to install `pyspark` module"
      ],
      "metadata": {
        "id": "b_0qPlclao37"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqgebMAwRfNo"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWZZxR7uVPw1"
      },
      "source": [
        "----\n",
        "Run the following block to import the necessary modules\n",
        "\n",
        "**Do not forget to upload the `challenge_task_data.csv` into the Google Colab environment.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scn7mBZ6J_xW"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import concat_ws\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import ArrayType, FloatType\n",
        "from pyspark.ml.feature import VectorAssembler, PCA\n",
        "from pyspark.ml.clustering import KMeans\n",
        "import plotly.express as px\n",
        "\n",
        "# Create the spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"myApp\") \\\n",
        "    .getOrCreate()\n",
        "# load the data\n",
        "df = pd.read_csv(\"challenge_task_data.csv\")\n",
        "\n",
        "# store the feature names\n",
        "features_column_names = [f\"feature_{i}\" for i in range(1, 513)]\n",
        "\n",
        "# update the column names\n",
        "df.columns = features_column_names\n",
        "\n",
        "# convert tha pandas dataframe to a spark dataframe\n",
        "data = spark.createDataFrame(df)\n",
        "\n",
        "# assemble the features\n",
        "assembler = VectorAssembler(inputCols=features_column_names, outputCol=\"features\")\n",
        "data = assembler.transform(data)\n",
        "\n",
        "# select the features\n",
        "data = data.select(\"features\")\n",
        "\n",
        "# cluster the data into 3 groups\n",
        "kmeans = KMeans(k=3,\n",
        "                seed=1,\n",
        "                featuresCol=\"features\",\n",
        "                predictionCol=\"cluster\")\n",
        "model = kmeans.fit(data)\n",
        "clustered_data = model.transform(data)\n",
        "clustered_data.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJSqEXllRfNo"
      },
      "source": [
        "Apply PCA to reduce the dimensionality of the `features` vector. call the output column `pcaFeatures`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73EXf737RfNo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the pyspark data frame into a pandas dataframe call it `pca_df`"
      ],
      "metadata": {
        "id": "rqHae9k2d3-5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l0fq98cOd-X9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract `x` and `y` from PCA features"
      ],
      "metadata": {
        "id": "NACoDfNBeYio"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q8--Ja1Keg9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use plotly express to visualize the vlusters in a 2D-scatterplot"
      ],
      "metadata": {
        "id": "uKbS6gb3dXWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the base cluster plot\n",
        "fig = px.scatter(\n",
        "    pca_df,\n",
        "    x='x',\n",
        "    y='y',\n",
        "    opacity=0.6,\n",
        "    size_max=4,\n",
        "    color= pca_df.cluster.astype(str),\n",
        "    title='2D Visualization of Clusters with Recently Viewed Products',\n",
        "    labels={'x': 'PCA Component 1', 'y': 'PCA Component 2'},\n",
        "    category_orders={'cluster': list(range(4))},\n",
        "    # show the product id in the tooltip\n",
        ")\n",
        "\n",
        "# Update layout to add legend title and adjust plot settings\n",
        "fig.update_layout(legend_title_text='Clusters', legend=dict(x=1, y=1), width=600, height=500)"
      ],
      "metadata": {
        "id": "ve_uisW0dbO5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}